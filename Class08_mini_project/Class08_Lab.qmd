---
title: "Class08: Breast Cancer Mini Project"
author: "Kyle Canturia (A17502778)"
format: pdf
toc: true
---

## Background

In today's class we will apply the methods and techniques clustering and PCA to help make sense of a real world breast cancer FNA biopsy data set. 

```{r}
fna.data <- "WisconsinCancer.csv"
wisc.df <- read.csv(fna.data, row.names=1)
```

```{r}
wisc.data <- wisc.df[,-1]
#removes first column from dataset, we don't want to use this for machine learning models, instead will use it later to compare results to the expert diagnosis
```

```{r}
diagnosis <- wisc.df$diagnosis
#stores diagnosis column from original dataset in variable "diagnosis"
```

> Q1: How many observations are in this dataset?

```{r}
View(wisc.data)
```
There are 569 observations in this dataset. 

> Q2: How many of the observations have a malignant diagnosis?

```{r}
table(wisc.df$diagnosis)
sum(wisc.df$diagnosis == "M")
```
```{r}
table(wisc.df$diagnosis == "M")
```

There are 212 observations with a malignant diagnosis. 

> Q3: How many variables/features in the data are suffixed with _mean?

```{r}
sum(grepl("_mean$", colnames(wisc.data)))
#either works
length(grep("_mean", colnames(wisc.data)))
```
There are 10 observations that are suffixed with "mean". 

## Principal Component Analysis 

The main function here is `prcomp()` and we want to make sure we set the optional argument `scale=TRUE`:

```{r}
wisc.pr <- prcomp(wisc.data, scale = T)
summary(wisc.pr)
```

> Q4: What proportion of orginal variance is captured by the first principal component (PC1)?

44.27% of the original variance is captured by PC1. 

> Q5: How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

It takes 3 PCs to describe at least 70% of the original variance. 

> Q6: How many principal components are required to describe at least 90% of the original variance in the data?

It takes 7 PCs to describe at least 90% of the original variance. 

## Interpreting PCA results

> Q7: What stands out about this plot? Is it easy or difficult to understand and why?

```{r}
biplot(wisc.pr)
```

The main thing that stands out about this plot is that all the clusters are all really close together. This density makes the plot difficult to understand as it's hardd to pick out individual clusters. 

Our main PCA "score plot" or "PC plot" of results:

```{r}
library(ggplot2)
```
```{r}
ggplot(wisc.pr$x) +
  aes(PC1,PC2, col=diagnosis) +
  geom_point()
```

> Q8: Generate a similar plot for PCs 1 and 3, what do you notice about these plots?

```{r}
ggplot(wisc.pr$x) +
  aes(PC1, PC3, col=diagnosis) +
  geom_point()
```

I noticed that in this plot, PC1 appears to be flipped relative to the x-plane and is now upside down compared to the first plot. I notice that in both plots, there's still a pretty clear distinction between diagnosis "B" and "M". 

## Communicating PCA results

> Q9: For the first principal component, what is the main component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC. Are there any features with larger contributions than this one?

## Hierarchical Clustering

> Q10: What is the height at which the clustering model has 4 clusters?

```{r}
data.scaled <- scale(wisc.data)
```
```{r}
data.dist <- dist(data.scaled)
```
```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
```
```{r}
plot(wisc.hclust)
abline(h = 19, col="red", lty=2)
```

The clustering model has 4 clusters at a height of 19. 

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=4)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
table(wisc.hclust.clusters)
```

> Q12: Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

I believe that the `ward.D2` method gives the best results for the same dataset. The other methods connect clusters based on distance, while `ward.D2` groups based on minimizing the variance within a cluster. This helps to dampen some of the noise, which is especially helpful with such a large dataset. 

## Combining Methods

Here we will take our PCA resuluts and use those an input for clustering. In other words our `wisc.pr$x` scores that we plotted above (the main output from PCA - how the data lie on our new principal component axis/variables) and use a subset of the PCs that capture the most variance as input for `hclust()`.

```{r}
pc.dist <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(pc.dist, method = "ward.D2")
plot(wisc.pr.hclust)
```

Cut the dendrogram/tree into two main groups/clusters:

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
table(grps, diagnosis)
```

I want to know how clustering in `grps` with values of 1 or 2 correspond to the expert `diagnosis`

```{r}
table(grps, diagnosis)
```

My clustering **groups 1** are mostly "M" diagnosis (179) and my clustering **group 2** are mostly "B" diagnosis (333)

24 FP
179 TP
333 TN
33 FN

## Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```
> Q13: How well does the newly created `hclust` model with two clusters separate out the two "M" and "B" diagnoses?

It does well, there is a clear majority of either diagnosis between each cluster with only a small minority of the other diagnosis. 

> Q14: How well do the hierarchical clustering models you created in the previous sections (i.e. without first doing PCA) do in terms of separating the diagnoses? 

```{r}
table(wisc.hclust.clusters, diagnosis)
```

They do not do as well for separating the diagnoses, there are multiple clusters instead of 2 clear clusters which have a single diagnosis dominating them. 

> Q16: Which patient should be prioritized for follow up based on the results?

Patient 2 should be prioritized for follow up based on the results as they reflect a malignant diagnosis





















